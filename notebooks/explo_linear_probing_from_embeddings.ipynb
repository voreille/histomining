{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from openslide import OpenSlide\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from histomining.models.foundation_models import load_model\n",
    "from histomining.models.linear_probing import LinearProbingFromEmbeddings\n",
    "from histomining.data.torch_datasets import TileDataset\n",
    "from histomining.utils import get_device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device(gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39105d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_dir = Path(\"/mnt/nas6/data/CPTAC\")\n",
    "tiles_root_dir = \"/mnt/nas7/data/Personal/Valentin/histopath/tiles_20x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc91599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_path(wsi_id, wsi_dir):\n",
    "    wsi_paths = [f for f in wsi_dir.rglob(wsi_id + \".svs\")]\n",
    "    if len(wsi_paths) > 1:\n",
    "        raise ValueError(f\"Multiple WSI files found for {wsi_id}: {wsi_paths}\")\n",
    "    return wsi_paths[0]\n",
    "\n",
    "def get_tiles_dir(wsi_id, tiles_root_dir):\n",
    "    tiles_dir_match = list(Path(tiles_root_dir).glob(f\"./*/{wsi_id}\"))\n",
    "    if len(list(tiles_dir_match)) != 1:\n",
    "        raise ValueError(f\"Multiple tile directories found for {wsi_id}: {list(tiles_dir_match)}\")\n",
    "    tiles_dir = tiles_dir_match[0] / \"tiles\"\n",
    "    return tiles_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess, embedding_dim, autocast_dtype = load_model(\"UNI2\",device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probing = LinearProbingFromEmbeddings.load_from_checkpoint(\"/home/valentin/workspaces/histomining/models/linear_probing_from_embeddings/linear_probing_weights_uni2_mag_key_0.ckpt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_id = \"C3L-00001-21\"\n",
    "# wsi_id = \"C3L-00893-22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e54921",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_path = get_wsi_path(wsi_id, wsi_dir)\n",
    "wsi = OpenSlide(wsi_path)\n",
    "thumbnail = wsi.get_thumbnail((800,800))\n",
    "display(thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87250c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_paths = list(get_tiles_dir(wsi_id, tiles_root_dir).glob(\"*.png\"))\n",
    "tile_ids = [tile_path.stem for tile_path in tile_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tiles: {len(tile_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7acecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TileDataset(tile_paths=tile_paths, preprocess=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572aaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "preds = []\n",
    "logits = []\n",
    "with torch.inference_mode():\n",
    "    for batch in tqdm(dataloader, desc=\"Computing embeddings\"):\n",
    "        batch_embeddings = model(batch.to(device))\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        batch_logits = linear_probing(batch_embeddings)\n",
    "        logits.append(batch_logits.cpu().numpy())\n",
    "        preds.append(F.softmax(batch_logits, dim=1).cpu().numpy())\n",
    "\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "logits = np.concatenate(logits, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(attention_map, thumbnail):\n",
    "    # Normalize the attention map between 0 and 1\n",
    "    attention_norm = (attention_map - attention_map.min()) / (\n",
    "        attention_map.max() - attention_map.min()\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Show WSI thumbnail\n",
    "    plt.imshow(thumbnail, cmap=\"gray\" if thumbnail.ndim == 2 else None)\n",
    "\n",
    "    # Overlay attention heatmap with transparency\n",
    "    plt.imshow(attention_norm, cmap=\"jet\", alpha=0.5)  # alpha adjusts transparency\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"WSI Thumbnail with Attention Overlay\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4541cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_attention_map(\n",
    "    attention_scores: np.array,\n",
    "    tile_ids: list,\n",
    "    tile_size: int = 224,\n",
    "    tile_mpp: float = 1.0,\n",
    "    wsi_path: str = None,\n",
    "    output_mpp: float = 2.0,\n",
    "    return_thumbnail: bool = True,\n",
    ") -> np.array:\n",
    "    attention_scores = np.squeeze(attention_scores)\n",
    "    wsi = OpenSlide(wsi_path)\n",
    "    mpp_x, mpp_y = (\n",
    "        wsi.properties.get(\"openslide.mpp-x\"),\n",
    "        wsi.properties.get(\"openslide.mpp-y\"),\n",
    "    )\n",
    "    if mpp_x is None or mpp_y is None:\n",
    "        raise ValueError(\"Microns per pixel not found in WSI properties.\")\n",
    "    if mpp_x != mpp_y:\n",
    "        raise ValueError(\"Microns per pixel values are not equal.\")\n",
    "\n",
    "    mpp_x = float(mpp_x)\n",
    "    resizing_factor = mpp_x / output_mpp\n",
    "    wsi_width, wsi_height = wsi.level_dimensions[0]\n",
    "    width = int(wsi_width * resizing_factor)\n",
    "    height = int(wsi_height * resizing_factor)\n",
    "\n",
    "    attention_map = np.zeros((height, width), dtype=np.float32)\n",
    "    resized_tile_size = int(tile_size * resizing_factor * tile_mpp / mpp_x)\n",
    "    for tile_idx, tile_id in enumerate(tile_ids):\n",
    "        x, y = get_position_from_tile_id(tile_id)\n",
    "        resized_x = int(x * resizing_factor)\n",
    "        resized_y = int(y * resizing_factor)\n",
    "        attention_map[\n",
    "            resized_y : resized_y + resized_tile_size,\n",
    "            resized_x : resized_x + resized_tile_size,\n",
    "        ] = attention_scores[tile_idx]\n",
    "\n",
    "    if return_thumbnail:\n",
    "        thumbnail = wsi.get_thumbnail((width, height))\n",
    "        return attention_map, thumbnail\n",
    "    return attention_map\n",
    "\n",
    "\n",
    "def get_position_from_tile_id(tile_id):\n",
    "    # tile_id = tile_id.decode(\"utf-8\")\n",
    "    parts = tile_id.split(\"__x\")[1].split(\"_y\")\n",
    "    x = int(parts[0])\n",
    "    y = int(parts[1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map, thumbnail = compute_attention_map(preds[:,1], tile_ids, tile_size=224, tile_mpp=0.5, wsi_path=wsi_path, output_mpp=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map_thresholded = np.where(attention_map > 0.5, attention_map, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec25314",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_map(attention_map, np.array(thumbnail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f55954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701605f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
